{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "common_prompt_template = PromptTemplate.from_template(\n",
    "    \"\"\"You are an expert in {dialect}. Your job is to read and understand the following [Database Schema] description, along with any [Reference Information], and then use your knowledge of {dialect} to generate an SQL statement that answers the [User Question]. Pay attention to the [Database Schema], only use tables and columns that are in the [Database Schema]. Avoid using any other tables or columns that are not in the [Database Schema].\n",
    "\n",
    "[User Question]\n",
    "{user_question}\n",
    "\n",
    "[Database Schema]\n",
    "{schema}\n",
    "\n",
    "[Reference Information]\n",
    "None\n",
    "\n",
    "ONLY OUTPUT THE SQL STATEMENT, NO OTHER TEXT.\n",
    "\"\"\"\n",
    ")\n",
    "xiyan_en_prompt_template = PromptTemplate.from_template(\n",
    "    \"\"\"You are an expert in {dialect}. Your job is to read and understand the following 【Schema】 description, along with any 【Evidence】, and then use your knowledge of {dialect} to generate an SQL statement that answers the 【Question】.\n",
    "\n",
    "【Question】\n",
    "{user_question}\n",
    "\n",
    "【Schema】\n",
    "{schema}\n",
    "\n",
    "【Evidence】\n",
    "{example_rows}\n",
    "\n",
    "【Question】\n",
    "{user_question}\n",
    "```sql\n",
    "\"\"\"\n",
    ")\n",
    "xiyan_cn_prompt_template = PromptTemplate.from_template(\n",
    "    \"\"\"你是一名{dialect}专家，现在需要阅读并理解下面的【数据库schema】描述，以及可能用到的【参考信息】，并运用{dialect}知识生成sql语句回答【用户问题】。\n",
    "【用户问题】\n",
    "{user_question}\n",
    "\n",
    "【数据库schema】\n",
    "{schema}\n",
    "\n",
    "【参考信息】\n",
    "None\n",
    "\n",
    "【用户问题】\n",
    "{user_question}\n",
    "\n",
    "```sql\"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_config = {\n",
    "    \"llama32_3b\": {\n",
    "        \"model_name\": \"llama3.2:3b\",\n",
    "        \"model_config_init\": {\n",
    "            \"temperature\": 0.0,\n",
    "        },\n",
    "        \"prompt_template\": common_prompt_template,\n",
    "        \"inference_type\": \"ollama\",\n",
    "    },\n",
    "    \"sqlllama_7b_16\": {\n",
    "        \"model_name\": \"hf.co/mradermacher/SQL-Llama-v0.5-GGUF:F16\",\n",
    "        \"model_config_init\": {\n",
    "            \"temperature\": 0.0,\n",
    "        },\n",
    "        \"prompt_template\": common_prompt_template,\n",
    "        \"inference_type\": \"ollama\",\n",
    "    },\n",
    "    \"xiyansql_7b_8_en_prompt\": {\n",
    "        \"model_name\": \"hf.co/mradermacher/XiYanSQL-QwenCoder-7B-2504-GGUF:Q8_0\",\n",
    "        \"model_config_init\": {\n",
    "            \"temperature\": 0.0,\n",
    "        },\n",
    "        \"prompt_template\": xiyan_en_prompt_template,\n",
    "        \"inference_type\": \"ollama\",\n",
    "    },\n",
    "    \"xiyansql_7b_8_cn_prompt\": {\n",
    "        \"model_name\": \"hf.co/mradermacher/XiYanSQL-QwenCoder-7B-2504-GGUF:Q8_0\",\n",
    "        \"model_config_init\": {\n",
    "            \"temperature\": 0.0,\n",
    "        },\n",
    "        \"prompt_template\": xiyan_cn_prompt_template,\n",
    "        \"inference_type\": \"ollama\",\n",
    "    },\n",
    "    \"xiyansql_7b_16_en_prompt\": {\n",
    "        \"model_name\": \"hf.co/mradermacher/XiYanSQL-QwenCoder-7B-2504-GGUF:F16\",\n",
    "        \"model_config_init\": {\"temperature\": 0.1, \"top_p\": 0.8},\n",
    "        \"prompt_template\": xiyan_en_prompt_template,\n",
    "        \"inference_type\": \"ollama\",\n",
    "    },\n",
    "    \"xiyansql_7b_16_cn_prompt\": {\n",
    "        \"model_name\": \"hf.co/mradermacher/XiYanSQL-QwenCoder-7B-2504-GGUF:F16\",\n",
    "        \"model_config_init\": {\"temperature\": 0.1, \"top_p\": 0.8},\n",
    "        \"prompt_template\": xiyan_cn_prompt_template,\n",
    "        \"inference_type\": \"ollama\",\n",
    "    },\n",
    "    \"xiyansql_7b_16_en_prompt_vllm\": {\n",
    "        \"model_name\": \"XGenerationLab/XiYanSQL-QwenCoder-7B-2504\",\n",
    "        \"model_config_init\": {\"temperature\": 0.1, \"top_p\": 0.8},\n",
    "        \"prompt_template\": xiyan_en_prompt_template,\n",
    "        \"inference_type\": \"vllm\",\n",
    "    },\n",
    "    \"xiyansql_7b_16_en_prompt_w_ex\": {\n",
    "        \"model_name\": \"hf.co/mradermacher/XiYanSQL-QwenCoder-7B-2504-GGUF:F16\",\n",
    "        \"model_config_init\": {\"temperature\": 0.1, \"top_p\": 0.8},\n",
    "        \"prompt_template\": xiyan_en_prompt_template,\n",
    "        \"inference_type\": \"ollama\",\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_ollama import ChatOllama\n",
    "from langchain_community.llms import VLLM\n",
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "tqdm.pandas()\n",
    "\n",
    "\n",
    "class ModelCreater:\n",
    "    def __init__(self):\n",
    "        self.llm = None\n",
    "        self.model_name = None\n",
    "        self.infer_type = None\n",
    "\n",
    "    def create_model(self, model_config: dict):\n",
    "        if (\n",
    "            self.llm\n",
    "            and self.model_name == model_config[\"model_name\"]\n",
    "            and self.infer_type == model_config[\"inference_type\"]\n",
    "        ):\n",
    "            return self.llm\n",
    "        else:\n",
    "            # shutdown created vllm\n",
    "            if self.infer_type == \"vllm\":\n",
    "                pass\n",
    "\n",
    "            if model_config[\"inference_type\"] == \"ollama\":\n",
    "                self.llm = ChatOllama(\n",
    "                    model=model_config[\"model_name\"],\n",
    "                    **model_config[\"model_config_init\"],\n",
    "                )\n",
    "            elif model_config[\"inference_type\"] == \"vllm\":\n",
    "                self.llm = VLLM(\n",
    "                    model=model_config[\"model_name\"],\n",
    "                    trust_remote_code=True,\n",
    "                    **model_config[\"model_config_init\"],\n",
    "                )\n",
    "            else:\n",
    "                raise ValueError(\n",
    "                    f\"Inference type {model_config['inference_type']} not supported\"\n",
    "                )\n",
    "        self.model_name = model_config[\"model_name\"]\n",
    "        self.infer_type = model_config[\"inference_type\"]\n",
    "        return self.llm\n",
    "\n",
    "\n",
    "model_creater = ModelCreater()\n",
    "\n",
    "\n",
    "def benchmark_model(\n",
    "    model: str, input_file_path: str, output_file_path: str, dialect: str\n",
    "):\n",
    "    config = model_config[model]\n",
    "    llm = model_creater.create_model(config)\n",
    "    prompt_template = config[\"prompt_template\"]\n",
    "\n",
    "    def generate_sql(\n",
    "        user_question: str,\n",
    "        schema_list: list[str],\n",
    "        dialect: str,\n",
    "        example_rows: list[str],\n",
    "    ):\n",
    "        message = prompt_template.invoke(\n",
    "            {\n",
    "                \"user_question\": user_question,\n",
    "                \"schema\": \"\\n\\n\".join(schema_list),\n",
    "                \"dialect\": dialect,\n",
    "                \"example_rows\": \"\\n\\n\".join(example_rows),\n",
    "            }\n",
    "        )\n",
    "        message = llm.invoke(message)\n",
    "        if not isinstance(message, str):\n",
    "            message = message.content\n",
    "        # format the message to be a valid sql statement\n",
    "        message = (\n",
    "            message.strip()\n",
    "            .replace(\"```sql\", \"\")\n",
    "            .replace(\"```\", \"\")\n",
    "            .replace(\"\\n\", \"\")\n",
    "            .replace(\"\\t\", \"\")\n",
    "        )\n",
    "        # print(f\"Generated answer for question: {user_question[:20]}...\")\n",
    "        return message\n",
    "\n",
    "    df = pd.read_csv(input_file_path)\n",
    "    inference_df = df.assign(\n",
    "        answer=lambda df_: df_.progress_apply(\n",
    "            lambda row: generate_sql(\n",
    "                row.question, row.schemas, dialect, row.example_rows\n",
    "            ),\n",
    "            axis=1,\n",
    "        )\n",
    "    )\n",
    "    with open(output_file_path, \"w+\") as f:\n",
    "        answer_list = inference_df[\"answer\"].tolist()\n",
    "        f.write(\"\\n\".join(answer_list))\n",
    "\n",
    "    return inference_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_list = [\n",
    "    # \"llama32_3b\",\n",
    "    # \"sqlllama_7b_16\",\n",
    "    # \"xiyansql_7b_8_en_prompt\",\n",
    "    # \"xiyansql_7b_8_cn_prompt\",\n",
    "    # \"xiyansql_7b_16_en_prompt\",\n",
    "    # \"xiyansql_7b_16_cn_prompt\",\n",
    "    # \"xiyansql_7b_16_en_prompt_vllm\",\n",
    "    \"xiyansql_7b_16_en_prompt_w_ex\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Benchmarking xiyansql_7b_16_en_prompt_w_ex, dev dataset\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f5712e5387dc426c851455bce7370ce4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1034 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Benchmarking xiyansql_7b_16_en_prompt_w_ex, test dataset\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1faf6dcb9ae249c99acccb079216d3a0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2147 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for dataset in [\"dev\", \"test\"]:\n",
    "    for model_name in test_list:\n",
    "        dialect = \"sqlite\"\n",
    "        input_file_path = f\"prepare_data/{dataset}_input.csv\"\n",
    "        output_file_path = f\"inference_data/{model_name}_{dataset}_inf.txt\"\n",
    "        print(f\"Benchmarking {model_name}, {dataset} dataset\")\n",
    "        inference_df = benchmark_model(\n",
    "            model_name, input_file_path, output_file_path, dialect\n",
    "        )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
